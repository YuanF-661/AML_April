import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
import numpy as np
import matplotlib.pyplot as plt
import argparse
from datetime import datetime
import librosa

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from model import DrumClassifier
from dataset import preprocess, adjust_length, create_dataset
from config import batch_size, sample_rate, target_length, learning_rate, num_epochs
from distillation import PANNsTeacher, distillation_loss, convert_mfcc_to_waveform


# æ·»åŠ å‚æ•°è§£æ
def parse_args():
    parser = argparse.ArgumentParser(description='é¼“æœºåˆ†ç±»å™¨è®­ç»ƒ - çŸ¥è¯†è’¸é¦ç‰ˆ')
    parser.add_argument('--data_folder', type=str, default=None,
                        help='æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--panns_model', type=str, required=True,
                        help='PANNsé¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆå¦‚Cnn14_mAP=0.431.pthï¼‰')
    parser.add_argument('--alpha', type=float, default=0.5,
                        help='çŸ¥è¯†è’¸é¦ä¸­ç¡¬ç›®æ ‡ä¸è½¯ç›®æ ‡çš„æƒé‡å¹³è¡¡å‚æ•°')
    parser.add_argument('--temperature', type=float, default=2.0,
                        help='çŸ¥è¯†è’¸é¦ä¸­çš„æ¸©åº¦å‚æ•°')
    parser.add_argument('--batch_size', type=int, default=batch_size,
                        help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--epochs', type=int, default=num_epochs,
                        help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--learning_rate', type=float, default=learning_rate,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--use_raw_audio', action='store_true',
                        help='æ˜¯å¦ä½¿ç”¨åŸå§‹éŸ³é¢‘æ³¢å½¢è¿›è¡Œè’¸é¦ï¼ˆæ¨èï¼‰')
    parser.add_argument('--save_dir', type=str, default='models',
                        help='æ¨¡å‹ä¿å­˜ç›®å½•')

    return parser.parse_args()


def train_with_distillation(model, train_loader, val_loader, teacher_model,
                            optimizer, device, num_epochs,
                            alpha=0.5, temperature=2.0, use_raw_audio=True):
    """
    ä½¿ç”¨çŸ¥è¯†è’¸é¦è®­ç»ƒæ¨¡å‹

    Args:
        model: å­¦ç”Ÿæ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        teacher_model: PANNsæ•™å¸ˆæ¨¡å‹
        optimizer: ä¼˜åŒ–å™¨
        device: è®¡ç®—è®¾å¤‡
        num_epochs: è®­ç»ƒè½®æ•°
        alpha: ç¡¬ç›®æ ‡å’Œè½¯ç›®æ ‡æŸå¤±çš„æƒé‡å¹³è¡¡å‚æ•°
        temperature: è½¯åŒ–æ•™å¸ˆé¢„æµ‹çš„æ¸©åº¦å‚æ•°
        use_raw_audio: æ˜¯å¦ä½¿ç”¨åŸå§‹éŸ³é¢‘æ³¢å½¢è¿›è¡Œè’¸é¦

    Returns:
        è®­ç»ƒå†å²è®°å½•
    """



    print(f"å¼€å§‹è®­ç»ƒï¼Œä½¿ç”¨çŸ¥è¯†è’¸é¦ (alpha={alpha}, temperature={temperature})")
    model.to(device)

    # åœ¨åˆ›å»ºå­¦ç”Ÿæ¨¡å‹ä¹‹åæ·»åŠ æ­¤æ£€æŸ¥
    def check_requires_grad(model):
        for name, param in model.named_parameters():
            if not param.requires_grad:
                print(f"è­¦å‘Š: å‚æ•° {name} ä¸éœ€è¦æ¢¯åº¦ï¼")
                param.requires_grad = True

    # ä½¿ç”¨
    check_requires_grad(model)

    # æ™®é€šåˆ†ç±»æŸå¤±
    criterion = nn.CrossEntropyLoss()

    # è®°å½•è®­ç»ƒå†å²
    history = {
        'train_loss': [], 'val_loss': [],
        'train_type_acc': [], 'val_type_acc': [],
        'train_machine_acc': [], 'val_machine_acc': [],
        'distill_loss': []
    }

    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        distill_loss_sum = 0.0
        type_correct = 0
        machine_correct = 0
        total = 0

        for batch_idx, batch in enumerate(train_loader):
            # åªæ‰“å°ä¸€ä¸ª batchï¼Œè°ƒè¯• batch çš„ç»“æ„
            # for batch in train_loader:
            #     print(f"\nğŸ“¦ len(batch): {len(batch)}")
            #
            #     for i, item in enumerate(batch):
            #         print(f"\nğŸ”¹ batch[{i}] (type: {type(item)})")
            #
            #         if isinstance(item, torch.Tensor):
            #             print(f"  shape: {item.shape}")
            #             print(f"  values (å‰2ä¸ª):\n{item[:2]}")
            #
            #         elif isinstance(item, tuple):
            #             print(f"  â¬‡ï¸ å†…éƒ¨ tuple é•¿åº¦: {len(item)}")
            #             for j, sub_item in enumerate(item):
            #                 print(f"    â–ªï¸ item[{j}] (type: {type(sub_item)})")
            #                 if isinstance(sub_item, torch.Tensor):
            #                     print(f"      shape: {sub_item.shape}")
            #                     print(f"      values (å‰2ä¸ª):\n{sub_item[:2]}")
            #                 else:
            #                     print(f"      value: {sub_item}")
            #         else:
            #             print(f"  å†…å®¹: {item}")
            #
            #     break  # åªçœ‹ä¸€ä¸ª batchï¼Œé¿å…åˆ·å±

            # æ‰¹é‡æ•°æ®å¤„ç†
            if len(batch) == 2 and not use_raw_audio:
                # æ ‡å‡†æ ¼å¼ï¼š(mfcc, (type_labels, machine_labels))
                mfcc, (type_labels, machine_labels) = batch

                # å°†MFCCè½¬æ¢ä¸ºæ³¢å½¢ï¼ˆè¿‘ä¼¼ï¼‰
                waveform = convert_mfcc_to_waveform(mfcc, sr=sample_rate)

            elif len(batch) == 3 and use_raw_audio:
                # ä¿®æ”¹è¿™é‡Œï¼Œæ­£ç¡®å¤„ç†åˆ—è¡¨å½¢å¼çš„æ ‡ç­¾
                mfcc, waveform, labels_list = batch

                # ä»åˆ—è¡¨ä¸­è·å–æ ‡ç­¾
                type_labels = labels_list[0]  # ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯é¼“ç±»å‹æ ‡ç­¾
                machine_labels = labels_list[1]  # ç¬¬äºŒä¸ªå…ƒç´ æ˜¯é¼“æœºå‹å·æ ‡ç­¾

                # æ£€æŸ¥æ˜¯å¦æœ‰one-hotç¼–ç 
                if len(labels_list) > 2:
                    type_onehot = labels_list[2]  # ç¬¬ä¸‰ä¸ªå…ƒç´ æ˜¯one-hotç¼–ç 

            elif len(batch) == 3 and not use_raw_audio:
                # one-hotå¢å¼ºæ ¼å¼ï¼š(mfcc, (type_labels, machine_labels, type_onehot))
                mfcc, (type_labels, machine_labels, type_onehot) = batch

                # å°†MFCCè½¬æ¢ä¸ºæ³¢å½¢ï¼ˆè¿‘ä¼¼ï¼‰
                waveform = convert_mfcc_to_waveform(mfcc, sr=sample_rate)

            elif len(batch) == 4:
                # åŒ…å«åŸå§‹æ³¢å½¢å’Œone-hotç¼–ç çš„æ ¼å¼
                # (mfcc, waveform, (type_labels, machine_labels, type_onehot))
                mfcc, waveform, (type_labels, machine_labels, type_onehot) = batch

            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ‰¹é‡æ ¼å¼: {len(batch)}")

            # æ•°æ®ç§»åˆ°è®¾å¤‡
            mfcc = mfcc.to(device)
            waveform = waveform.to(device)
            type_labels = type_labels.to(device)
            machine_labels = machine_labels.to(device)

            # å…ˆè·å–é¼“ç±»å‹å’Œé¼“æœºå‹å·çš„æ•°é‡
            num_drum_types = len(torch.unique(type_labels))
            num_drum_machines = len(torch.unique(machine_labels))

            # è·å–æ•™å¸ˆæ¨¡å‹çš„é¢„æµ‹
            with torch.no_grad():
                teacher_outputs = teacher_model.predict(waveform)

                # å°†æ•™å¸ˆè¾“å‡ºè½¬æ¢ä¸ºå¯ä»¥åœ¨è®¡ç®—å›¾ä¸­ä½¿ç”¨ä½†ä¸è®¡ç®—æ¢¯åº¦çš„å¼ é‡
                teacher_type_logits = teacher_outputs[:, :num_drum_types].clone().detach()
                teacher_machine_logits = teacher_outputs[:, -num_drum_machines:].clone().detach()

                # ç¡®ä¿ç»´åº¦åŒ¹é…
                if teacher_type_logits.size(1) < num_drum_types:
                    padding = torch.zeros(teacher_type_logits.size(0),
                                          num_drum_types - teacher_type_logits.size(1),
                                          device=device)
                    teacher_type_logits = torch.cat([teacher_type_logits, padding], dim=1)

                if teacher_machine_logits.size(1) < num_drum_machines:
                    padding = torch.zeros(teacher_machine_logits.size(0),
                                          num_drum_machines - teacher_machine_logits.size(1),
                                          device=device)
                    teacher_machine_logits = torch.cat([teacher_machine_logits, padding], dim=1)

            # å‰å‘ä¼ æ’­ï¼ˆå­¦ç”Ÿæ¨¡å‹ï¼‰
            if 'type_onehot' in locals():
                type_onehot = type_onehot.to(device)
                student_type_logits, student_machine_logits = model(mfcc, type_onehot)
            else:
                student_type_logits, student_machine_logits = model(mfcc)

            # è®¡ç®—ç¡¬ç›®æ ‡æŸå¤±ï¼ˆå¸¸è§„äº¤å‰ç†µï¼‰
            type_ce_loss = criterion(student_type_logits, type_labels)
            machine_ce_loss = criterion(student_machine_logits, machine_labels)
            hard_loss = type_ce_loss + machine_ce_loss

            # åœ¨è®¡ç®—çŸ¥è¯†è’¸é¦æŸå¤±å‰æ·»åŠ 
            # print(
            #     f"æ‰¹æ¬¡ {batch_idx}: Student type: {student_type_logits.shape}, Teacher type: {teacher_type_logits.shape}")
            # print(
            #     f"æ‰¹æ¬¡ {batch_idx}: Student machine: {student_machine_logits.shape}, Teacher machine: {teacher_machine_logits.shape}")

            # è®¡ç®—çŸ¥è¯†è’¸é¦æŸå¤±
            type_distill_loss = distillation_loss(
                student_type_logits, teacher_type_logits.detach(),  # æ˜ç¡®detachæ•™å¸ˆè¾“å‡º
                labels=None, alpha=0, temperature=temperature
            )

            machine_distill_loss = distillation_loss(
                student_machine_logits, teacher_machine_logits.detach(),  # æ˜ç¡®detachæ•™å¸ˆè¾“å‡º
                labels=None, alpha=0, temperature=temperature
            )

            soft_loss = type_distill_loss + machine_distill_loss

            # ç»„åˆç¡¬ç›®æ ‡å’Œè½¯ç›®æ ‡æŸå¤±
            loss = alpha * hard_loss + (1 - alpha) * soft_loss

            # åå‘ä¼ æ’­å’Œä¼˜åŒ–
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # ç»Ÿè®¡
            train_loss += loss.item()
            distill_loss_sum += soft_loss.item()

            _, type_preds = torch.max(student_type_logits, 1)
            _, machine_preds = torch.max(student_machine_logits, 1)

            type_correct += (type_preds == type_labels).sum().item()
            machine_correct += (machine_preds == machine_labels).sum().item()
            total += type_labels.size(0)

            # æ˜¾ç¤ºè¿›åº¦
            if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(train_loader):
                print(f"Epoch [{epoch + 1}/{num_epochs}], "
                      f"Batch [{batch_idx + 1}/{len(train_loader)}], "
                      f"Loss: {loss.item():.4f}, "
                      f"Distill Loss: {soft_loss.item():.4f}")

        print(f"Student type logits shape: {student_type_logits.shape}")
        print(f"Teacher type logits shape: {teacher_type_logits.shape}")

        # è®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
        train_loss /= len(train_loader)
        distill_loss_avg = distill_loss_sum / len(train_loader)
        train_type_acc = 100.0 * type_correct / total
        train_machine_acc = 100.0 * machine_correct / total

        # ä¿å­˜åˆ°å†å²è®°å½•
        history['train_loss'].append(train_loss)
        history['distill_loss'].append(distill_loss_avg)
        history['train_type_acc'].append(train_type_acc)
        history['train_machine_acc'].append(train_machine_acc)

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_type_correct = 0
        val_machine_correct = 0
        val_total = 0

        with torch.no_grad():
            for batch in val_loader:
                # æ‰¹é‡æ•°æ®å¤„ç†ï¼ˆä¸è®­ç»ƒé˜¶æ®µç›¸åŒï¼‰
                if len(batch) == 2 and not use_raw_audio:
                    mfcc, (type_labels, machine_labels) = batch
                    waveform = convert_mfcc_to_waveform(mfcc, sr=sample_rate)
                elif len(batch) == 3 and use_raw_audio:
                    # ä¿®æ”¹è¿™é‡Œï¼Œä¸è®­ç»ƒé˜¶æ®µä¿æŒä¸€è‡´
                    mfcc, waveform, labels_list = batch
                    type_labels = labels_list[0]
                    machine_labels = labels_list[1]
                    if len(labels_list) > 2:
                        type_onehot = labels_list[2]
                elif len(batch) == 3 and not use_raw_audio:
                    mfcc, (type_labels, machine_labels, type_onehot) = batch
                    waveform = convert_mfcc_to_waveform(mfcc, sr=sample_rate)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æ‰¹é‡æ ¼å¼: {len(batch)}")

                # æ•°æ®ç§»åˆ°è®¾å¤‡
                mfcc = mfcc.to(device)
                type_labels = type_labels.to(device)
                machine_labels = machine_labels.to(device)

                # å­¦ç”Ÿæ¨¡å‹å‰å‘ä¼ æ’­
                if 'type_onehot' in locals():
                    type_onehot = type_onehot.to(device)
                    student_type_logits, student_machine_logits = model(mfcc, type_onehot)
                else:
                    student_type_logits, student_machine_logits = model(mfcc)

                # è®¡ç®—éªŒè¯æŸå¤±ï¼ˆä»…ä½¿ç”¨ç¡¬ç›®æ ‡æŸå¤±ï¼‰
                type_loss = criterion(student_type_logits, type_labels)
                machine_loss = criterion(student_machine_logits, machine_labels)
                loss = type_loss + machine_loss

                val_loss += loss.item()

                # è®¡ç®—å‡†ç¡®ç‡
                _, type_preds = torch.max(student_type_logits, 1)
                _, machine_preds = torch.max(student_machine_logits, 1)

                val_type_correct += (type_preds == type_labels).sum().item()
                val_machine_correct += (machine_preds == machine_labels).sum().item()
                val_total += type_labels.size(0)

        # è®¡ç®—å¹³å‡éªŒè¯æŸå¤±å’Œå‡†ç¡®ç‡
        val_loss /= len(val_loader)
        val_type_acc = 100.0 * val_type_correct / val_total
        val_machine_acc = 100.0 * val_machine_correct / val_total

        # ä¿å­˜åˆ°å†å²è®°å½•
        history['val_loss'].append(val_loss)
        history['val_type_acc'].append(val_type_acc)
        history['val_machine_acc'].append(val_machine_acc)

        # æ‰“å°è®­ç»ƒä¿¡æ¯
        print(f"Epoch [{epoch + 1}/{num_epochs}], "
              f"Train Loss: {train_loss:.4f}, "
              f"Distill Loss: {distill_loss_avg:.4f}, "
              f"Train Type Acc: {train_type_acc:.2f}%, "
              f"Train Machine Acc: {train_machine_acc:.2f}%, "
              f"Val Loss: {val_loss:.4f}, "
              f"Val Type Acc: {val_type_acc:.2f}%, "
              f"Val Machine Acc: {val_machine_acc:.2f}%")

    return history


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()

    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # è®¾ç½®æ•°æ®ç›®å½•
    data_folder = args.data_folder if args.data_folder else None
    if data_folder is None:
        # å¦‚æœæœªæä¾›ï¼Œå°è¯•ä»configå¯¼å…¥
        from config import data_folder

    print(f"æ•°æ®ç›®å½•: {data_folder}")
    if not os.path.exists(data_folder):
        print(f"é”™è¯¯: æ•°æ®ç›®å½• '{data_folder}' ä¸å­˜åœ¨")
        return

    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)

    # åŠ è½½æ•°æ®é›†
    print("åŠ è½½æ•°æ®é›†...")
    try:
        # åŠ è½½æ•°æ®é›†æ—¶ä¼ å…¥ use_raw_audio å‚æ•°
        train_dataset, val_dataset, test_dataset, metadata = create_dataset(
            data_folder, sample_rate=sample_rate, target_length=target_length,
            use_raw_audio=args.use_raw_audio
        )
    except Exception as e:
        print(f"åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
        return

    print(f"æ•°æ®é›†åŠ è½½å®Œæˆ: {len(train_dataset)} è®­ç»ƒæ ·æœ¬, "
          f"{len(val_dataset)} éªŒè¯æ ·æœ¬, {len(test_dataset)} æµ‹è¯•æ ·æœ¬")

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)

    # åŠ è½½PANNsæ•™å¸ˆæ¨¡å‹
    print(f"åŠ è½½PANNsæ•™å¸ˆæ¨¡å‹: {args.panns_model}")
    try:
        teacher_model = PANNsTeacher(args.panns_model, device=device)
    except Exception as e:
        print(f"åŠ è½½æ•™å¸ˆæ¨¡å‹å¤±è´¥: {e}")
        return

    # åˆ›å»ºå­¦ç”Ÿæ¨¡å‹
    print("åˆ›å»ºå­¦ç”Ÿæ¨¡å‹...")
    model = DrumClassifier(
        input_channels=1,  # MFCCæ˜¯å•é€šé“
        num_drum_types=metadata['num_drum_types'],
        num_drum_machines=metadata['num_drum_machines'],
        input_height=metadata['input_height'],
        input_width=metadata['input_width']
    )

    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)

    # ä½¿ç”¨çŸ¥è¯†è’¸é¦è®­ç»ƒæ¨¡å‹
    history = train_with_distillation(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        teacher_model=teacher_model,
        optimizer=optimizer,
        device=device,
        num_epochs=args.epochs,
        alpha=args.alpha,
        temperature=args.temperature,
        use_raw_audio=args.use_raw_audio
    )

    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plt.figure(figsize=(12, 10))

    # æŸå¤±æ›²çº¿
    plt.subplot(2, 2, 1)
    plt.plot(history['train_loss'], label='Train Loss')
    plt.plot(history['val_loss'], label='Val Loss')
    plt.plot(history['distill_loss'], label='Distillation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()

    # é¼“ç±»å‹å‡†ç¡®ç‡æ›²çº¿
    plt.subplot(2, 2, 2)
    plt.plot(history['train_type_acc'], label='Train Type Acc')
    plt.plot(history['val_type_acc'], label='Val Type Acc')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.title('Drum Type Accuracy')
    plt.legend()

    # é¼“æœºå‹å·å‡†ç¡®ç‡æ›²çº¿
    plt.subplot(2, 2, 3)
    plt.plot(history['train_machine_acc'], label='Train Machine Acc')
    plt.plot(history['val_machine_acc'], label='Val Machine Acc')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.title('Drum Machine Accuracy')
    plt.legend()

    # ä¿å­˜å›¾è¡¨
    os.makedirs('results', exist_ok=True)
    plt.tight_layout()
    plt.savefig('results/distillation_training_history.png')

    # åœ¨ main å‡½æ•°ä¸­çš„ä¿å­˜æ¨¡å‹å’Œå…ƒæ•°æ®éƒ¨åˆ†
    # æŸ¥æ‰¾å­˜åœ¨çš„ç‰ˆæœ¬å·
    def get_next_version(dir_path, prefix):
        version = 1
        while os.path.exists(os.path.join(dir_path, f"{prefix}_v{version}.pth")):
            version += 1
        return version

    # ä¿å­˜æ¨¡å‹
    timestamp = datetime.now().strftime("%Y-%m-%d")
    version = get_next_version(args.save_dir, f"DrumClassifier_Distilled_{timestamp}")
    model_filename = f"DrumClassifier_Distilled_{timestamp}_v{version}.pth"
    model_path = os.path.join(args.save_dir, model_filename)
    torch.save(model.state_dict(), model_path)

    # ä¿å­˜å…ƒæ•°æ®
    metadata_filename = f"metadata_distilled_{timestamp}_v{version}.pth"
    metadata_path = os.path.join(args.save_dir, metadata_filename)

    # æ›´æ–°å…ƒæ•°æ®ä»¥åŒ…å«è’¸é¦ä¿¡æ¯å’Œç‰ˆæœ¬å·
    distill_metadata = metadata.copy()
    distill_metadata.update({
        'model_path': model_path,
        'version': version,
        'distillation': {
            'teacher_model': args.panns_model,
            'alpha': args.alpha,
            'temperature': args.temperature,
            'use_raw_audio': args.use_raw_audio
        }
    })

    torch.save(distill_metadata, metadata_path)

    print(f"æ¨¡å‹å·²ä¿å­˜è‡³: {model_path} (ç‰ˆæœ¬: v{version})")
    print(f"å…ƒæ•°æ®å·²ä¿å­˜è‡³: {metadata_path}")

    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹
    print("\nåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹...")
    model.eval()
    test_loss = 0.0
    test_type_correct = 0
    test_machine_correct = 0
    test_total = 0

    with torch.no_grad():
        for batch in test_loader:
            # å¤„ç†æ‰¹é‡æ•°æ®
            if len(batch) == 2 and not args.use_raw_audio:
                mfcc, (type_labels, machine_labels) = batch
            elif len(batch) == 3 and args.use_raw_audio:
                # å¤„ç†åŒ…å«åŸå§‹æ³¢å½¢çš„æ‰¹æ¬¡
                mfcc, waveform, labels_list = batch
                type_labels = labels_list[0]
                machine_labels = labels_list[1]
                if len(labels_list) > 2:
                    type_onehot = labels_list[2]
            elif len(batch) == 3 and not args.use_raw_audio:
                mfcc, (type_labels, machine_labels, type_onehot) = batch
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ‰¹é‡æ ¼å¼: {len(batch)}")

            # æ•°æ®ç§»åˆ°è®¾å¤‡
            mfcc = mfcc.to(device)
            type_labels = type_labels.to(device)
            machine_labels = machine_labels.to(device)

            # å‰å‘ä¼ æ’­
            if len(batch) == 3:
                type_onehot = type_onehot.to(device)
                type_outputs, machine_outputs = model(mfcc, type_onehot)
            else:
                type_outputs, machine_outputs = model(mfcc)

            # è®¡ç®—æŸå¤±
            criterion = nn.CrossEntropyLoss()
            type_loss = criterion(type_outputs, type_labels)
            machine_loss = criterion(machine_outputs, machine_labels)
            loss = type_loss + machine_loss

            test_loss += loss.item()

            # è®¡ç®—å‡†ç¡®ç‡
            _, type_preds = torch.max(type_outputs, 1)
            _, machine_preds = torch.max(machine_outputs, 1)

            test_type_correct += (type_preds == type_labels).sum().item()
            test_machine_correct += (machine_preds == machine_labels).sum().item()
            test_total += type_labels.size(0)

    # è®¡ç®—å¹³å‡æµ‹è¯•æŸå¤±å’Œå‡†ç¡®ç‡
    test_loss /= len(test_loader)
    test_type_acc = 100.0 * test_type_correct / test_total
    test_machine_acc = 100.0 * test_machine_correct / test_total

    print(f"æµ‹è¯•æŸå¤±: {test_loss:.4f}")
    print(f"æµ‹è¯•é¼“ç±»å‹å‡†ç¡®ç‡: {test_type_acc:.2f}%")
    print(f"æµ‹è¯•é¼“æœºå‹å·å‡†ç¡®ç‡: {test_machine_acc:.2f}%")

    # æ¯”è¾ƒä¸æœªä½¿ç”¨çŸ¥è¯†è’¸é¦çš„åŸå§‹æ¨¡å‹çš„æ€§èƒ½å·®å¼‚
    print("\né€šè¿‡çŸ¥è¯†è’¸é¦æ”¹è¿›çš„ç»“æœï¼š")
    if 'test_results' in metadata and 'type_accuracy' in metadata['test_results']:
        original_type_acc = metadata['test_results']['type_accuracy']
        original_machine_acc = metadata['test_results']['machine_accuracy']

        type_improvement = test_type_acc - original_type_acc
        machine_improvement = test_machine_acc - original_machine_acc

        print(f"é¼“ç±»å‹å‡†ç¡®ç‡: {original_type_acc:.2f}% -> {test_type_acc:.2f}% ({type_improvement:+.2f}%)")
        print(f"é¼“æœºå‹å·å‡†ç¡®ç‡: {original_machine_acc:.2f}% -> {test_machine_acc:.2f}% ({machine_improvement:+.2f}%)")
    else:
        print("æ²¡æœ‰åŸå§‹æ¨¡å‹çš„æµ‹è¯•ç»“æœç”¨äºæ¯”è¾ƒ")

    print("\nçŸ¥è¯†è’¸é¦è®­ç»ƒå®Œæˆ!")


if __name__ == "__main__":
    main()